SupportVectorMachine
=======================

决策树算法的优点
-----------------------

* 分类精度高；
* 生成的模式简单；
* 对噪声数据有很好的健壮性。

基本思想
-----------------------

* 树以代表训练样本的单个结点开始。
* 树以代表训练样本的单个结点开始。
* 否则，算法选择最有分类能力的属性作为决策树的当前结点．
* 根据当前决策结点属性取值的不同，将训练样本数据集tlI分为若干子集，每个取值形成一个分枝，<br>
    有几个取值形成几个分枝。匀针对上一步得到的一个子集，重复进行先前步骤，递4'I形成每个划分样本上的决策树。<br>
    一旦一个属性出现在一个结点上，就不必在该结点的任何后代考虑它。
* 递归划分步骤仅当下列条件之一成立时停止：
    * 给定结点的所有样本属于同一类。
    * 没有剩余属性可以用来进一步划分样本．在这种情况下．使用多数表决，将给定的结点转换成树叶，<br>
    并以样本中元组个数最多的类别作为类别标记，同时也可以存放该结点样本的类别分布，
    * 如果某一分枝tc，没有满足该分支中已有分类的样本，则以样本的多数类创建一个树叶。
